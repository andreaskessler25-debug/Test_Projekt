{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f82b3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: holidays in c:\\daten\\weiterbildung\\python\\portfolioprojekt\\test_projekt\\.venv\\lib\\site-packages (0.83)\n",
      "Requirement already satisfied: python-dateutil in c:\\daten\\weiterbildung\\python\\portfolioprojekt\\test_projekt\\.venv\\lib\\site-packages (from holidays) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\daten\\weiterbildung\\python\\portfolioprojekt\\test_projekt\\.venv\\lib\\site-packages (from python-dateutil->holidays) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "142f06cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ holidays geladen aus: c:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\holidays\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import holidays\n",
    "print(\"‚úÖ holidays geladen aus:\", holidays.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prep.ipynb\n",
    "# --------------------------\n",
    "# Notebook: DE Load + Price + Full Weather\n",
    "# Purpose: Download, clean, join, feature-engineer hourly 60-min resolution dataset\n",
    "\n",
    "\n",
    "# Cell 1: Imports & env setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import holidays\n",
    "import requests\n",
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3e1776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Anfrage URL: https://archive-api.open-meteo.com/v1/archive?latitude=52.52&longitude=13.405&start_date=2015-01-01&end_date=2025-10-29&hourly=temperature_2m,wind_speed_10m,cloudcover&timezone=Europe/Berlin\n",
      "‚úÖ Wetterdaten gespeichert unter: ..\\data\\raw\\open_meteo_berlin_hourly.csv\n",
      "                     temp_C  wind_m_s  cloud_cover_pct\n",
      "time                                                  \n",
      "2015-01-01 00:00:00     4.0      14.2             87.0\n",
      "2015-01-01 01:00:00     3.8      14.4             71.0\n",
      "2015-01-01 02:00:00     3.6      14.9             69.0\n",
      "2015-01-01 03:00:00     3.3      14.6             95.0\n",
      "2015-01-01 04:00:00     3.0      14.1             82.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "raw_path = Path(\"../data/raw\")\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Beispiel-Koordinate: Deutschland (Berlin)\n",
    "latitude  = 52.52\n",
    "longitude = 13.405\n",
    "start_date = \"2015-01-01\"\n",
    "end_date   = \"2025-10-29\"\n",
    "\n",
    "url = (\n",
    "    f\"https://archive-api.open-meteo.com/v1/archive?\"\n",
    "    f\"latitude={latitude}&longitude={longitude}\"\n",
    "    f\"&start_date={start_date}&end_date={end_date}\"\n",
    "    f\"&hourly=temperature_2m,wind_speed_10m,cloudcover\"\n",
    "    f\"&timezone=Europe/Berlin\"\n",
    ")\n",
    "\n",
    "print(\"üîç Anfrage URL:\", url)\n",
    "r = requests.get(url)\n",
    "r.raise_for_status()\n",
    "data = r.json()\n",
    "\n",
    "df = pd.DataFrame(data[\"hourly\"])\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "df = df.set_index(\"time\")\n",
    "\n",
    "# Umbenennen\n",
    "df = df.rename(columns={\n",
    "    \"temperature_2m\": \"temp_C\",\n",
    "    \"wind_speed_10m\": \"wind_m_s\",\n",
    "    \"cloudcover\": \"cloud_cover_pct\"\n",
    "})\n",
    "\n",
    "# Optional resample auf 60min (wenn n√∂tig)\n",
    "df = df.resample(\"60min\").mean()\n",
    "\n",
    "# Speichern\n",
    "out_file = raw_path / \"open_meteo_berlin_hourly.csv\"\n",
    "df.to_csv(out_file)\n",
    "print(\"‚úÖ Wetterdaten gespeichert unter:\", out_file)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145c7d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "OPS_DATA_CSV = DATA_DIR / 'time_series_60min_singleindex.csv'\n",
    "DWD_WEATHER_CSV = DATA_DIR / 'dwd_hourly_weather.csv'\n",
    "OUTPUT_DIR = Path('./processed')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2af5fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verf√ºgbare DE-Spalten (Auszug):\n",
      "['DE_load_actual_entsoe_transparency', 'DE_load_forecast_entsoe_transparency', 'DE_solar_capacity', 'DE_solar_generation_actual', 'DE_solar_profile', 'DE_wind_capacity', 'DE_wind_generation_actual', 'DE_wind_profile', 'DE_wind_offshore_capacity', 'DE_wind_offshore_generation_actual', 'DE_wind_offshore_profile', 'DE_wind_onshore_capacity', 'DE_wind_onshore_generation_actual', 'DE_wind_onshore_profile', 'DE_50hertz_load_actual_entsoe_transparency'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load</th>\n",
       "      <th>price</th>\n",
       "      <th>wind</th>\n",
       "      <th>solar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utc_timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00+00:00</th>\n",
       "      <td>41151.0</td>\n",
       "      <td>56.1</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 00:00:00+00:00</th>\n",
       "      <td>41151.0</td>\n",
       "      <td>56.1</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 01:00:00+00:00</th>\n",
       "      <td>40135.0</td>\n",
       "      <td>56.1</td>\n",
       "      <td>9054.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 02:00:00+00:00</th>\n",
       "      <td>39106.0</td>\n",
       "      <td>56.1</td>\n",
       "      <td>9070.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01 03:00:00+00:00</th>\n",
       "      <td>38765.0</td>\n",
       "      <td>56.1</td>\n",
       "      <td>9163.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              load  price    wind  solar\n",
       "utc_timestamp                                           \n",
       "2014-12-31 23:00:00+00:00  41151.0   56.1  8852.0   71.0\n",
       "2015-01-01 00:00:00+00:00  41151.0   56.1  8852.0   71.0\n",
       "2015-01-01 01:00:00+00:00  40135.0   56.1  9054.0   71.0\n",
       "2015-01-01 02:00:00+00:00  39106.0   56.1  9070.0   71.0\n",
       "2015-01-01 03:00:00+00:00  38765.0   56.1  9163.0   71.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zeitbereich: 2014-12-31 23:00:00+00:00 ‚Üí 2020-09-30 23:00:00+00:00\n",
      "Anzahl Zeilen: 50,401\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load OPSD data\n",
    "# opsd_df = pd.read_csv(OPS_DATA_CSV, parse_dates=['utc_timestamp'], index_col='utc_timestamp')\n",
    "opsd_df = pd.read_csv(\n",
    "    OPS_DATA_CSV,\n",
    "    sep=\",\",\n",
    "    parse_dates=[\"utc_timestamp\"],\n",
    "    index_col=\"utc_timestamp\",\n",
    ")\n",
    "\n",
    "print(\"Verf√ºgbare DE-Spalten (Auszug):\")\n",
    "print([col for col in opsd_df.columns if col.startswith(\"DE\")][:15], \"...\")\n",
    "\n",
    "# === Relevante deutsche Spalten ausw√§hlen ===\n",
    "opsd_df = opsd_df[\n",
    "    [\n",
    "        \"DE_load_actual_entsoe_transparency\",  # Stromverbrauch (real)\n",
    "        \"DE_LU_price_day_ahead\",               # Day-Ahead-Preis (DE+LU)\n",
    "        \"DE_wind_generation_actual\",           # Wind (gesamt)\n",
    "        \"DE_solar_generation_actual\",          # Solar (gesamt)\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\n",
    "        \"DE_load_actual_entsoe_transparency\": \"load\",\n",
    "        \"DE_LU_price_day_ahead\": \"price\",\n",
    "        \"DE_wind_generation_actual\": \"wind\",\n",
    "        \"DE_solar_generation_actual\": \"solar\",\n",
    "    }\n",
    ")\n",
    "# Auf Stundenebene sicherstellen (falls L√ºcken)\n",
    "opsd_df = opsd_df.resample(\"60min\").mean()\n",
    "\n",
    "# Fehlende Werte auff√ºllen\n",
    "opsd_df = opsd_df.interpolate(limit_direction=\"both\")\n",
    "\n",
    "# Vorschau\n",
    "display(opsd_df.head())\n",
    "print(f\"\\nZeitbereich: {opsd_df.index.min()} ‚Üí {opsd_df.index.max()}\")\n",
    "print(f\"Anzahl Zeilen: {len(opsd_df):,}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb8bbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98a89364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìç Lade Daten f√ºr NORTH (Station 10147)\n",
      "‚ö†Ô∏è Keine Datei f√ºr TU 10147 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr FF 10147 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr SD 10147 gefunden.\n",
      "\n",
      "üìç Lade Daten f√ºr SOUTH (Station 10865)\n",
      "‚ö†Ô∏è Keine Datei f√ºr TU 10865 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr FF 10865 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr SD 10865 gefunden.\n",
      "\n",
      "üìç Lade Daten f√ºr EAST (Station 10488)\n",
      "‚ö†Ô∏è Keine Datei f√ºr TU 10488 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr FF 10488 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr SD 10488 gefunden.\n",
      "\n",
      "üìç Lade Daten f√ºr WEST (Station 10400)\n",
      "‚ö†Ô∏è Keine Datei f√ºr TU 10400 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr FF 10400 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr SD 10400 gefunden.\n",
      "\n",
      "üìç Lade Daten f√ºr CENTER (Station 10637)\n",
      "‚ö†Ô∏è Keine Datei f√ºr TU 10637 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr FF 10637 gefunden.\n",
      "‚ö†Ô∏è Keine Datei f√ºr SD 10637 gefunden.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1Ô∏è‚É£ Einstellungen\n",
    "# ---------------------------------------------\n",
    "BASE_URL = \"https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly\"\n",
    "CATEGORIES = {\n",
    "    \"TU\": \"Lufttemperatur\",\n",
    "    \"FF\": \"Windgeschwindigkeit\",\n",
    "    \"SD\": \"Sonnenscheindauer\"\n",
    "}\n",
    "\n",
    "STATIONS = {\n",
    "    \"NORTH\": \"10147\",   # Hamburg\n",
    "    \"SOUTH\": \"10865\",   # M√ºnchen\n",
    "    \"EAST\": \"10488\",    # Dresden\n",
    "    \"WEST\": \"10400\",    # D√ºsseldorf\n",
    "    \"CENTER\": \"10637\"   # Erfurt\n",
    "}\n",
    "\n",
    "SAVE_PATH = Path(\"data/raw/weather_germany\")\n",
    "SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2Ô∏è‚É£ Hilfsfunktion: URL pr√ºfen\n",
    "# ---------------------------------------------\n",
    "def url_exists(url: str) -> bool:\n",
    "    resp = requests.head(url)\n",
    "    return resp.status_code == 200\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3Ô∏è‚É£ Downloadfunktion (sucht automatisch passende Datei)\n",
    "# ---------------------------------------------\n",
    "def download_dwd_file(cat: str, station: str):\n",
    "    # Neuere Struktur seit 2024:\n",
    "    # /.../hourly/{cat}/historical/ oder /recent/\n",
    "    base_paths = [f\"{BASE_URL}/{cat}/recent/\", f\"{BASE_URL}/{cat}/historical/\"]\n",
    "    file_patterns = [\n",
    "        f\"stundenwerte_{cat}_{station}_akt.zip\",\n",
    "        f\"stundenwerte_{cat}_{station}_hist.zip\",\n",
    "        f\"stundenwerte_{cat}_{station}.zip\"\n",
    "    ]\n",
    "\n",
    "    for base in base_paths:\n",
    "        for filename in file_patterns:\n",
    "            url = base + filename\n",
    "            if url_exists(url):\n",
    "                print(f\"‚¨áÔ∏è Lade {cat} von {url}\")\n",
    "                r = requests.get(url)\n",
    "                z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "                z.extractall(SAVE_PATH / f\"{cat}_{station}\")\n",
    "                return True\n",
    "    print(f\"‚ö†Ô∏è Keine Datei f√ºr {cat} {station} gefunden.\")\n",
    "    return False\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4Ô∏è‚É£ Alles herunterladen\n",
    "# ---------------------------------------------\n",
    "all_dfs = []\n",
    "for region, station in STATIONS.items():\n",
    "    print(f\"\\nüìç Lade Daten f√ºr {region} (Station {station})\")\n",
    "    region_data = {}\n",
    "\n",
    "    for cat in CATEGORIES.keys():\n",
    "        if download_dwd_file(cat, station):\n",
    "            # Entpackte Datei suchen\n",
    "            extracted_files = list((SAVE_PATH / f\"{cat}_{station}\").glob(\"produkt_*.txt\"))\n",
    "            if not extracted_files:\n",
    "                continue\n",
    "            df = pd.read_csv(\n",
    "                extracted_files[0], sep=\";\", na_values=\"-999\",\n",
    "                parse_dates=[\"MESS_DATUM\"], index_col=\"MESS_DATUM\"\n",
    "            )\n",
    "            region_data[cat] = df\n",
    "\n",
    "    if region_data:\n",
    "        # Kombinieren und umbenennen\n",
    "        combined = pd.DataFrame(index=region_data[\"TU\"].index)\n",
    "        combined[\"temp\"] = region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb188540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Lade Wetterdaten ...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\weather_germany_avg_2015_2020.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2Ô∏è‚É£ Laden der Daten\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìÇ Lade Wetterdaten ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m weather_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweather_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìÇ Lade OPSD-Daten ...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m opsd_df = pd.read_csv(opsd_path, parse_dates=[\u001b[33m\"\u001b[39m\u001b[33mutc_timestamp\u001b[39m\u001b[33m\"\u001b[39m], index_col=\u001b[33m\"\u001b[39m\u001b[33mutc_timestamp\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Daten\\Weiterbildung\\Python\\Portfolioprojekt\\Test_Projekt\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data\\\\weather_germany_avg_2015_2020.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 1Ô∏è‚É£ Pfade definieren\n",
    "# ---------------------------------------------\n",
    "weather_path = Path(\"data/weather_germany_avg_2015_2020.csv\")\n",
    "opsd_path = Path(\"data/time_series_60min_singleindex.csv\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2Ô∏è‚É£ Laden der Daten\n",
    "# ---------------------------------------------\n",
    "print(\"üìÇ Lade Wetterdaten ...\")\n",
    "weather_df = pd.read_csv(weather_path, parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "\n",
    "print(\"üìÇ Lade OPSD-Daten ...\")\n",
    "opsd_df = pd.read_csv(opsd_path, parse_dates=[\"utc_timestamp\"], index_col=\"utc_timestamp\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3Ô∏è‚É£ Zeitraum anpassen\n",
    "# ---------------------------------------------\n",
    "start, end = weather_df.index.min(), weather_df.index.max()\n",
    "opsd_df = opsd_df.loc[start:end]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4Ô∏è‚É£ Relevante Spalten f√ºr Deutschland ausw√§hlen\n",
    "# ---------------------------------------------\n",
    "columns = [\n",
    "    \"DE_load_actual_entsoe_transparency\",\n",
    "    \"DE_LU_price_day_ahead\",\n",
    "    \"DE_solar_generation_actual\",\n",
    "    \"DE_wind_generation_actual\",\n",
    "    \"DE_wind_onshore_generation_actual\",\n",
    "    \"DE_wind_offshore_generation_actual\"\n",
    "]\n",
    "\n",
    "# Nur vorhandene Spalten √ºbernehmen\n",
    "opsd_selected = opsd_df[[col for col in columns if col in opsd_df.columns]].copy()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5Ô∏è‚É£ Zusammenf√ºhren mit Wetterdaten\n",
    "# ---------------------------------------------\n",
    "merged_df = pd.merge(\n",
    "    opsd_selected, weather_df,\n",
    "    how=\"inner\", left_index=True, right_index=True\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6Ô∏è‚É£ Fehlende Werte auff√ºllen\n",
    "# ---------------------------------------------\n",
    "merged_df = merged_df.interpolate(limit_direction=\"both\")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 7Ô∏è‚É£ Speichern\n",
    "# ---------------------------------------------\n",
    "output_path = Path(\"data/opsd_weather_merged_2015_2020.csv\")\n",
    "merged_df.to_csv(output_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Kombinierte Datei gespeichert unter:\\n{output_path}\")\n",
    "print(f\"üß≠ Zeitraum: {merged_df.index.min()} ‚Üí {merged_df.index.max()}\")\n",
    "print(f\"üìà Spalten: {list(merged_df.columns)}\")\n",
    "print(\"\\nüìä Vorschau:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load DWD weather data\n",
    "weather_df = pd.read_csv(DWD_WEATHER_CSV, parse_dates=['utc_timestamp'], index_col='utc_timestamp')\n",
    "# Assume weather_df has columns: temp, wind_speed, radiation, cloud_cover\n",
    "weather_df = weather_df.resample('60min').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24a701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Merge datasets\n",
    "full_df = opsd_df.join(weather_df, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d031372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Missing value handling\n",
    "full_df = full_df.ffill(limit=2) # forward fill up to 2 hours\n",
    "full_df['missing_weather_flag'] = full_df[['temp', 'wind_speed', 'radiation', 'cloud_cover']].isna().any(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f03cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Feature engineering - datetime features\n",
    "full_df['hour'] = full_df.index.hour\n",
    "full_df['day_of_week'] = full_df.index.dayofweek\n",
    "full_df['is_weekend'] = full_df['day_of_week'].isin([5,6]).astype(int)\n",
    "full_df['day_of_year'] = full_df.index.dayofyear\n",
    "# seasonal encoding\n",
    "full_df['hour_sin'] = np.sin(2*np.pi*full_df['hour']/24)\n",
    "full_df['hour_cos'] = np.cos(2*np.pi*full_df['hour']/24)\n",
    "full_df['dow_sin'] = np.sin(2*np.pi*full_df['day_of_week']/7)\n",
    "full_df['dow_cos'] = np.cos(2*np.pi*full_df['day_of_week']/7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7c98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays\n",
    "de_holidays = holidays.Germany()\n",
    "full_df['is_holiday'] = full_df.index.to_series().apply(lambda x: 1 if x in de_holidays else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Lag features (load and price)\n",
    "lags = [1,2,3,24,48,168]\n",
    "for lag in lags:\n",
    "full_df[f'DE_load_lag{lag}'] = full_df['DE_load_actual'].shift(lag)\n",
    "full_df[f'DE_price_lag{lag}'] = full_df['DE_price_day_ahead'].shift(lag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9170fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Rolling statistics\n",
    "windows = [3,24,168]\n",
    "for w in windows:\n",
    "full_df[f'DE_load_rollmean{w}'] = full_df['DE_load_actual'].rolling(w).mean()\n",
    "full_df[f'DE_load_rollstd{w}'] = full_df['DE_load_actual'].rolling(w).std()\n",
    "full_df[f'DE_price_rollmean{w}'] = full_df['DE_price_day_ahead'].rolling(w).mean()\n",
    "full_df[f'DE_price_rollstd{w}'] = full_df['DE_price_day_ahead'].rolling(w).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 10: Save train/val/test splits\n",
    "train_df = full_df[:'2022-12-31']\n",
    "val_df = full_df['2023-01-01':'2023-12-31']\n",
    "test_df = full_df['2024-01-01':]\n",
    "\n",
    "train_df.to_parquet(OUTPUT_DIR / 'train.parquet')\n",
    "val_df.to_parquet(OUTPUT_DIR / 'val.parquet')\n",
    "test_df.to_parquet(OUTPUT_DIR / 'test.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Quick sanity check\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "print(train_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpp-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
